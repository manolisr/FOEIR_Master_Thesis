# FOEIR_Master_Thesis

## Abstract
Recommendations should serve the needs of all their partakers. Not only should they try
to maximize userâ€™s utility, but also take responsibility for the notion of fairness they provide
towards the objects they rank. This work aims to capture the impact of F airness of Exposure
in Rankings framework as a bias mitigation and fairness of exposure allocation technique,
under a dynamic and implicit user feedback setting. To achieve this, two recommender system
pipelines are proposed. The one used as a baseline, generates its final recommendations solely
based on Bayesian P ersonalized Ranking. The second one, also employs F OEIR post-process
fairness recommendation algorithm. We observe, that although F OEIR mitigates various forms
of biases in the short run, past the 120th recommendation round mark, it overexposes popular
objects by 50% more on average, than the non-popular ones. Stricter constraints should be
adopted to ensure fairness on an object level, under a dynamic temporal recommendation
setting.

